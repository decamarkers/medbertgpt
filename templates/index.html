<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MedBert ChatBot</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/@unocss/runtime"></script>
  <script src="https://code.iconify.design/2/2.0.3/iconify.min.js"></script>
  <script src="https://unpkg.com/htmx.org@1.9.6" integrity="sha384-FhXw7b6AlE/jyjlZH5iHa/tTe9EpJ1Y55RjcgPbjeWMskSxZt1v9qkxLJWNJaGni" crossorigin="anonymous"></script>
  <style></style>
</head>
<body class="m-5">
  <h1>MedBert ChatBot</h1>
  <hr>
  <div id="answer-responses"></div>
  <br>
  <!-- add something that can allow voice -->
  <form hx-post="/process-question" hx-swap="beforeend" hx-target="#answer-responses" class="mb-3">
    <input type="text" id="question-input" name="question" placeholder="Type question here" class="form-control mb-3" x-webkit-speech>
    <button type="button" onclick="handleMic()" class="btn btn-secondary">
      <span class="iconify" data-icon="carbon:microphone-filled"></span>
    </button>
    <button type="submit" id="question-submit" class="btn btn-primary">Submit</button>
  </form>
  <br>

  <script>
    // test on chrome vs brave at home (there seems to be some stuff to think about)

    let recording = false
    let recognition
    let results

    function handleMic() {
      if (recording) {
        recognition.stop()
        recording = false
      } else {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
        recognition = new SpeechRecognition()
        recognition.continuous = true
        recognition.interimResults = true
        recognition.lang = "en-US"
        recognition.onstart = function() {console.log("Started")}
        recognition.onresult = async function(e) {results = e.results}
        recognition.onend = function() {
          console.log("Ended")
          for (let i = 0; i < results.length; i++) {
            const transcript = results[i][0].transcript
            console.log(transcript)
            document.getElementById("question-input").value = transcript
          }
        }
        recognition.onerror = function(e) {
          console.error(e)
          recognition.stop()
        }
        recognition.start()
        recording = true
      }
    }

    // let recorder
    // let chunks = []
    // async function handleMic3() {
    //   if (recording) {
    //     recorder.stop()
    //     recording = false
    //   } else {
    //     const stream = await navigator.mediaDevices.getUserMedia({audio: true})
    //     recorder = new MediaRecorder(stream)
    //     recorder.onstart = function() {console.log("Started")}
    //     recorder.ondataavailable = function({data}) {chunks.push(data)}
    //     recorder.onstop = async function() {
    //       const blob = new Blob(chunks, {type: "audio/wav"})
    //       console.log(blob)
    //       const formData = new FormData()
    //       formData.append("audio", blob, "temp_audio.wav")
    //       try {
    //         const res = await fetch("/process-deez", {
    //           method: "POST",
    //           mode: "cors",
    //           body: formData,
    //         })
    //         const data = await res.json()
    //         console.log(data.text)
    //         console.log("Ended")
    //       } catch (err) {
    //         console.error(err)
    //       }
    //     }
    //     recorder.start()
    //     recording = true
    //   }
    // }
  </script>
</body>
</html>